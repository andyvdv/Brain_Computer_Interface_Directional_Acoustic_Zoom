{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdX4feSRlK5m"
   },
   "source": [
    "# Basics of Keras\n",
    "[Keras homepage](https://keras.io/): Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "\n",
    "You may also consider installing the following optional dependencies:\n",
    "\n",
    "    cuDNN (recommended if you plan on running Keras on GPU).\n",
    "    HDF5 and h5py (required if you plan on saving Keras models to disk).\n",
    "    graphviz and pydot (used by visualization utilities to plot model graphs).\n",
    "\n",
    "\n",
    "\n",
    "**Installation**\n",
    "- for python2.x: pip install keras\n",
    "- for python3.x: pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXCkxN66lK5r"
   },
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5Y6or8WlK5z",
    "outputId": "6b680593-efe9-41d5-cbab-95cb45ac9c61"
   },
   "outputs": [],
   "source": [
    "import keras #importing keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRVqzWYOlK56"
   },
   "source": [
    "### Building a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0gvHouNlK58"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1) # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation # import linear layer (Dense) and activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDzYyA1elK6B"
   },
   "source": [
    "#### There are two ways of building a network in keras:\n",
    "- Sequential: It allows you to build your network by adding layers one-after-other in a sequence. One drawback of this method is that you can't build networks that share layers.\n",
    "- Functional API: Here you build a network like a graph. Hence more complex networks can be built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iGt64LrlK6D"
   },
   "source": [
    "### Sequential\n",
    "Read more: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xD4QxYJJlK6F"
   },
   "outputs": [],
   "source": [
    "#Simple 1 layer network \n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(32,)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4Uir5lnlK6L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # prints the summary of the network\n",
    "# Notice in Output Shape \"None\" is batch dims, 10 is feature dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRBwV7uelK6R"
   },
   "source": [
    "### Functional API\n",
    "Read more: https://keras.io/getting-started/functional-api-guide/\n",
    "\n",
    "Building the same network using functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvNLPYSXlK6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "inp = Input(shape=(32,))\n",
    "l1 = Dense(10)(inp) # See how the dense layer is pointing to inp\n",
    "act1 = Activation('softmax')(l1)\n",
    "\n",
    "model = Model(inputs=inp,outputs=act1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vay2JpAGlK6Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a 2 layer NN for binary classification:\n",
    "\n",
    "#Simple 1 layer network \n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(32,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ob97Mk1lK6e"
   },
   "source": [
    "#### Training\n",
    "\n",
    "- For supervised learning, we need (x,y) pairs to train our model. Where x is the input data and y is the corresponding ground truth.\n",
    "\n",
    "Lets sample x and y from a random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_oMIDh9PlK6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train[:5] [[0.18961835 0.22782933 0.31436441 0.60492097 0.42118645 0.20154231\n",
      "  0.1464898  0.91184627 0.44857941 0.79833144 0.37673675 0.85371272\n",
      "  0.11162496 0.35985571 0.50806736 0.54875875 0.65577184 0.12445216\n",
      "  0.65648235 0.00567807 0.2437447  0.20178268 0.06044281 0.39774929\n",
      "  0.07738228 0.33011013 0.14853353 0.07479315 0.41522254 0.36208229\n",
      "  0.11623708 0.94563485]\n",
      " [0.61799009 0.38103615 0.75890637 0.90310008 0.6331781  0.81894647\n",
      "  0.35891329 0.98387846 0.96395515 0.79767278 0.6192263  0.88742212\n",
      "  0.52880643 0.60072143 0.99474907 0.82542508 0.65820615 0.40970969\n",
      "  0.78961851 0.92498159 0.03949512 0.15158366 0.27075206 0.66877402\n",
      "  0.992547   0.54597122 0.74273553 0.84213526 0.31738051 0.08300837\n",
      "  0.95976396 0.5092413 ]\n",
      " [0.26097044 0.74079204 0.08321352 0.11562825 0.08276288 0.84831507\n",
      "  0.64554609 0.27027708 0.02614707 0.29105671 0.08533006 0.06484995\n",
      "  0.53946561 0.18399332 0.25517132 0.48928098 0.37180363 0.6808723\n",
      "  0.6032164  0.76570975 0.35413601 0.01767638 0.93933914 0.3386035\n",
      "  0.71775622 0.91039078 0.30458704 0.0657214  0.96935766 0.75938299\n",
      "  0.24949081 0.20531101]\n",
      " [0.02433203 0.05486666 0.54830027 0.26519798 0.33295071 0.75183106\n",
      "  0.67742875 0.13394347 0.53425974 0.62135714 0.47753935 0.90895525\n",
      "  0.5494551  0.23468755 0.72841211 0.59579982 0.92155468 0.47831909\n",
      "  0.05857922 0.46777016 0.13017851 0.55731158 0.13739143 0.50885406\n",
      "  0.39739712 0.609249   0.97371534 0.20252572 0.78075198 0.39760145\n",
      "  0.74626082 0.25120121]\n",
      " [0.43152862 0.73835166 0.41372697 0.40083976 0.292575   0.93882459\n",
      "  0.76479023 0.56705345 0.11529987 0.73878125 0.16195834 0.75789\n",
      "  0.31484516 0.66261844 0.28623452 0.02238012 0.67486591 0.72775238\n",
      "  0.9588958  0.81179636 0.73719707 0.06860675 0.42869005 0.9759333\n",
      "  0.25968359 0.75702982 0.86883645 0.05942577 0.56968654 0.9310615\n",
      "  0.95518176 0.50293091]]\n",
      "y_train[:5] [0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Create a set of random input vectors.\n",
    "# Both the input feature dimension and the input shape of the network should be consistent. Else you will get an error.\n",
    "x_train = np.random.rand(1000,32)\n",
    "y_train = np.random.binomial(1, 0.5, 1000) #Sampling from binomial distribution\n",
    "\n",
    "\n",
    "# Lets check our input and outputs\n",
    "\n",
    "print(\"x_train[:5]\",x_train[:5])\n",
    "print(\"y_train[:5]\",y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQ0WJgIElK6n"
   },
   "source": [
    "Similarly we will create our validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59iPKMtxlK6p"
   },
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "x_val = np.random.rand(250,32)\n",
    "y_val = np.random.binomial(1, 0.5, 250)\n",
    "\n",
    "# Test Set\n",
    "x_test = np.random.rand(250,32)\n",
    "y_test = np.random.binomial(1, 0.5, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LASTojjKlK6t"
   },
   "source": [
    "Now we will set other hyperparameter and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOy7j_HflK6v"
   },
   "outputs": [],
   "source": [
    "nb_batch = 32 # batch_size\n",
    "nb_epoch = 100 # no. of epochs\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Check keras documentation for other optimizers\n",
    "# Since the task here is classification, categorical_crossentropy loss will be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some callbacks to the model. This will allow us to eg. save the training/validation accuracy and loss at each epoch ( allows you to detect overfitting!), save the model, implement early stopping, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "csvLogger = keras.callbacks.CSVLogger(\"training_log.csv\")\n",
    "earlyStopping = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, csvLogger,earlyStopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLSxzEcqlK6-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 08:36:42.581388: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Keep shuffle True while training. Why?\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/y3/w8y39yms09jg30l75ycdw56h0000gn/T/__autograph_generated_file7xqtlb5g.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/rudi/.pyenv/versions/3.10.8/lib/python3.10/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=nb_batch, epochs=nb_epoch,callbacks=callbacks_list, verbose=1, validation_data=(x_val,y_val), shuffle=True)\n",
    "# Keep shuffle True while training. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ5vN0TLlK7E"
   },
   "source": [
    "#### Questions:\n",
    "- Why the training loss is decreasing? why validation loss is increasing?\n",
    "- Why the training accuracy is increasing? why the validation accuracy is almost constant?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-I1uJBVQlK7G"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x=x_test,y=y_test,batch_size=8)\n",
    "print(\"\\n\")\n",
    "print(\"test_loss:\",test_loss,\"    test_accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1Y-ezuPlK7L"
   },
   "source": [
    "## Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A98vt_hBlK7M"
   },
   "source": [
    "A convolutional neural network (or CNN) is a type of neural network comprises of typically following building blocks:\n",
    "- Convolutional Layer: These are a set of kernels/filters that convolve with a signal (1D: audio,EEG, etc; 2D: Images; 3D: Videos) to find particular patterns in it based on the kernel type. The kernels or filters are learnable through gradient descent.\n",
    "- Non-linearity: Relu, Sigmoid, tanh, etc.\n",
    "- Pooling layer: Downsamples the input signal, which also reduced the necessity to have a larger convolutional layer at the output. It also introduces small translation invariance to the input signal.\n",
    "- Fully connected layer/Linear layer: They are mainly used to model the actual decision process. Example: classifier.\n",
    "\n",
    "Hence, in contrast to classical methods where features are handcrafted and then we train a classifier on those features. CNN does both learning features and classification.\n",
    "\n",
    "![Basic CNN block](cnn_architecture.svg)\n",
    "Image source: https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjCtSgY9lK7O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Basics_keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
